{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []# 接受输入接受输出\n",
    "        \n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes outbound_nodes\n",
    "            \n",
    "        self.value = None\n",
    "        \n",
    "        self.gradients = {\n",
    "            # if is wx+b, this will be \n",
    "            # w: x 对w求偏导是x\n",
    "            # x: w 对x求偏导是w\n",
    "            # b: 1 对b求偏导是1\n",
    "        }\n",
    "        \"\"\"keys are the inputs to this node;\n",
    "        their values are the partials of this node with respect to that input \n",
    "        \\partial{node}{input_i} key是节点的输入，key对应的value是该节点对应于输入的部分\"\"\"\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        forward propagation\n",
    "        compute the output value on 'inbound_nodes' and store the result in self.value\n",
    "        前向传播\n",
    "        计算输入节点的输出值并在self.value上存储结果\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        an input node has no inbound nodes\n",
    "        so no need to pass anything to the node instantiator(实例化？)\n",
    "        没有输入节点的输入节点  tf.Variable\n",
    "\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "        \n",
    "    def forward(self, value=None):\n",
    "\n",
    "#         Only input node is the node where the value may be passed as an argument to forward().\n",
    "#         All other node implementations should get the value of the previous node from self.inbound_nodes\n",
    "        \n",
    "#         Example: \n",
    "#         val0: self.inbound_nodes[0].value\n",
    "\n",
    "        if value is not None:\n",
    "            self.value = value # 也可等于2* value等等不一样的计算方式\n",
    "            # 这是输入节点，当需要前向传播时，这个节点初始化自己的值\n",
    "         # 输入仅有值的子类，例如数据特征或者一个模型参数（权重、偏置项）\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1 \n",
    "            \n",
    "         # 输入N --> N1, N2 \n",
    "         # \\partial L / \\partial N \n",
    "         # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    \n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        # 执行Forward时，此节点根据定义计算值\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    \n",
    "    def  __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "        \n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "        \n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "        \n",
    "        # 为每一个出入节点初始化一个partial(偏置)偏导数\n",
    "        # initial a partial for each of the inbound_nodes\n",
    "        # np.zeros_like(n.value)为每个n.value生成一个同类型同样子的元素都是0的矩阵\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            # get the partial of the cost w.r.t this node\n",
    "            grad_cost = n.gradients[self] # 偏f/self\n",
    "            \n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            # 后面value.T 是因为考虑到numpy中数组的形状，对x求偏导\n",
    "            \n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            # 对w求偏导 偏f/偏linear * 偏linear/偏w\n",
    "            \n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "            # 对b求偏导  偏f/偏linear * 偏linear/偏w=偏f/偏linear * 1=grad_cost\n",
    "            # np.sum默认axis为None，表示将所有元素的值相加.对于二维数组,axis=1表示按行相加\n",
    "            # , axis=0表示按列相加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^ -x)\n",
    "        # y' = y(1 - y)\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            # get the partial of the cost with respect to this node\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to 保持所有的维度一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "        \n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "        \n",
    "        self.m = self.inputs[0].value.shape[0] # 表示y的元素个数\n",
    "        self.diff = y - a\n",
    "        \n",
    "        self.value = np.mean(self.diff ** 2)\n",
    "        # np.mean 求均值  axis=0、1，计算每一列、行的均值  1/m（y-a）^ 2\n",
    "        \n",
    "    def backward(self):\n",
    "        # 以下两个分别是对y求偏导，对a也就是yhat求偏导\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(outputnode, graph):\n",
    "    \n",
    "    # 运行排序节点的所有forward方法\n",
    "    # 实际应用中，经常有大量的数据而不是1个通过forward方法。因为样本可以并行处理。\n",
    "    # batch_size表示依次进入forward函数的样本的数量\n",
    "    # session.run()的过程\n",
    "    \n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        # 每个节点运行forward方法，依据拓扑排序的结果获得self.value\n",
    "    \n",
    "    for n in graph[::-1]:\n",
    "        n.backward()\n",
    "        \n",
    "    # 返回 outputnode.value\n",
    "    \n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"使用Kahn算法按拓扑顺序对一般节点排序。\n",
    "    ` feed_dict`：一种字典，其中key是“input”节点，value是向该节点提供的相应的值。\n",
    "     返回已排序节点的列表。 \"\"\"\n",
    "    \n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "    \n",
    "    G = {}\n",
    "    \n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out':set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "            \n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    \n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "        \n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            # 如果n是输入节点，把n的value设置为feed_dict[n]\n",
    "            # 否则，n的value通过他的输入来计算\n",
    "            \n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # 如果没有其他 引入的边添加到S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "                \n",
    "    return L\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # 有很多种更新、最优化方法，例如Adam，Mom\n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of examples = 506\n",
      "Epoch: 1, Loss: 210.963\n",
      "Epoch: 101, Loss: 7.718\n",
      "Epoch: 201, Loss: 5.483\n",
      "Epoch: 301, Loss: 5.498\n",
      "Epoch: 401, Loss: 5.026\n",
      "Epoch: 501, Loss: 4.389\n",
      "Epoch: 601, Loss: 4.430\n",
      "Epoch: 701, Loss: 3.836\n",
      "Epoch: 801, Loss: 4.008\n",
      "Epoch: 901, Loss: 4.243\n",
      "Epoch: 1001, Loss: 5.371\n",
      "Epoch: 1101, Loss: 4.753\n",
      "Epoch: 1201, Loss: 4.063\n",
      "Epoch: 1301, Loss: 4.862\n",
      "Epoch: 1401, Loss: 4.706\n",
      "Epoch: 1501, Loss: 4.576\n",
      "Epoch: 1601, Loss: 4.016\n",
      "Epoch: 1701, Loss: 4.134\n",
      "Epoch: 1801, Loss: 4.008\n",
      "Epoch: 1901, Loss: 3.870\n",
      "Epoch: 2001, Loss: 4.133\n",
      "Epoch: 2101, Loss: 4.117\n",
      "Epoch: 2201, Loss: 4.144\n",
      "Epoch: 2301, Loss: 4.321\n",
      "Epoch: 2401, Loss: 3.377\n",
      "Epoch: 2501, Loss: 3.670\n",
      "Epoch: 2601, Loss: 3.491\n",
      "Epoch: 2701, Loss: 3.775\n",
      "Epoch: 2801, Loss: 3.997\n",
      "Epoch: 2901, Loss: 4.007\n",
      "Epoch: 3001, Loss: 3.506\n",
      "Epoch: 3101, Loss: 3.716\n",
      "Epoch: 3201, Loss: 3.308\n",
      "Epoch: 3301, Loss: 3.644\n",
      "Epoch: 3401, Loss: 4.513\n",
      "Epoch: 3501, Loss: 3.339\n",
      "Epoch: 3601, Loss: 3.527\n",
      "Epoch: 3701, Loss: 4.058\n",
      "Epoch: 3801, Loss: 3.645\n",
      "Epoch: 3901, Loss: 3.892\n",
      "Epoch: 4001, Loss: 4.157\n",
      "Epoch: 4101, Loss: 3.509\n",
      "Epoch: 4201, Loss: 3.520\n",
      "Epoch: 4301, Loss: 4.442\n",
      "Epoch: 4401, Loss: 3.282\n",
      "Epoch: 4501, Loss: 3.780\n",
      "Epoch: 4601, Loss: 4.465\n",
      "Epoch: 4701, Loss: 3.607\n",
      "Epoch: 4801, Loss: 3.089\n",
      "Epoch: 4901, Loss: 4.102\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "选择新的网络架构和数据集。注意到权重和偏置是随机生成的。\n",
    "不需要改变任何事情，但可以随意调整来测试您的网络，play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "# load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0) # std是标准差 mean是求均值\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden,1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "# 样本总数\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print('total number of examples = {}'.format(m))\n",
    "\n",
    "# step4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # step1 随机抽取一批样本 randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size) \n",
    "        # resample重新取样 参数n_sample是生成样本的数量\n",
    "        \n",
    "        # Reset value of X and y Inputs 重置x和y的输入值\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "        \n",
    "        # step2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # 设置不重要的输出节点\n",
    "        \n",
    "        #step3\n",
    "        rate = 1e-2\n",
    "        \n",
    "        sgd_update(trainables,rate)\n",
    "        \n",
    "        loss += graph[-1].value\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e350f6c780>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHO5JREFUeJzt3W2MXNWd5/Hvv+rWQ3e7bbftNgbbwYTxBoh2IWyLMGK1m4FZY5jMmBdBYjS7sSIka1fsKiPN7izMG3bIoE3ehARpJxIK3nFGmSGISRYLoSGWIZrdFxCagUDAsDYeghs/dNvth36s6qr674t7qru6u6ofcD+Ye38fqVS3Tp2qPqe7un51zrm3rrk7IiKSPpnVboCIiKwOBYCISEopAEREUkoBICKSUgoAEZGUUgCIiKSUAkBEJKUUACIiKaUAEBFJqWi1GzCXTZs2+Y4dO1a7GSIinylvvPHGWXfvnq/eFR0AO3bsoLe3d7WbISLymWJmv1lIPU0BiYiklAJARCSlFAAiIimlABARSSkFgIhISikARERSSgEgIpJSiQyAUxfH+O7PP+D4wPBqN0VE5IqVyAAYGCrx5MvHOD4wstpNERG5YiUyAIq5LAClSm2VWyIicuVKZAAUorhb4xPVVW6JiMiVK6EBoBGAiMh8EhoAcbdKFY0ARERaSWQAaA1ARGR+iQyAfH0EMKEAEBFpJZEBkM0YuawxrikgEZGWEhkAEC8EawQgItJaggMgo0VgEZE5JDYAirmsFoFFROaQ2AAoRBkdCCYiMofEBkA+ymgEICIyhwUFgJmtN7PnzOx9MztiZr9tZhvM7JCZHQ3XXaGumdmTZnbMzN42s1sbnmdvqH/UzPYuV6cACpoCEhGZ00JHAN8H/t7dbwBuBo4ADwOH3X0ncDjcBrgH2Bku+4AfAJjZBuBR4MvAbcCj9dBYDsUoQ0lTQCIiLc0bAGa2FvjXwNMA7l529wvAHuBAqHYAuC9s7wF+5LFXgfVmdjVwN3DI3Qfd/TxwCNi9pL1pUMhlGdcIQESkpYWMAD4PDAD/y8zeNLMfmlkHcJW7nwII15tD/a3AiYbH94WyVuXLoqARgIjInBYSABFwK/ADd/8SMMLUdE8z1qTM5yif/mCzfWbWa2a9AwMDC2hec4UoQ1kjABGRlhYSAH1An7u/Fm4/RxwIZ8LUDuG6v6H+9obHbwNOzlE+jbs/5e497t7T3d29mL5Mo+MARETmNm8AuPtp4ISZfSEU3QW8BxwE6nvy7AWeD9sHga+HvYFuBy6GKaKXgF1m1hUWf3eFsmWhI4FFROYWLbDefwZ+bGZ54DjwDeLweNbMHgQ+Bu4PdV8E7gWOAaOhLu4+aGbfAl4P9R5z98El6UUThSjLuL4LSESkpQUFgLu/BfQ0ueuuJnUdeKjF8+wH9i+mgZ9WIacRgIjIXBJ7JHAhyjBRdaq1WevMIiJCggOgflYw7QkkItJcYgOgfl5gfSGciEhzCQ4AnRdYRGQuCQ6AcF5gLQSLiDSV2ACorwFoBCAi0lxiA2ByBKBjAUREmkpuAOTCIrCmgEREmkpuANQXgTUCEBFpKsEBoEVgEZG5JDYAtAgsIjK3xAaADgQTEZlbcgMgV58C0ghARKSZ5AbA5CKwRgAiIs0kNgCKGgGIiMwpsQGQz9bXABQAIiLNJDYAomyGKGPaDVREpIXEBgDUzwusEYCISDPJDoBcViMAEZEWEh0AxSijr4IQEWkh0QFQyGUZ1xSQiEhTyQ6AKKPjAEREWlhQAJjZR2b2jpm9ZWa9oWyDmR0ys6PhuiuUm5k9aWbHzOxtM7u14Xn2hvpHzWzv8nRpihaBRURaW8wI4Hfc/RZ37wm3HwYOu/tO4HC4DXAPsDNc9gE/gDgwgEeBLwO3AY/WQ2O5aBFYRKS1y5kC2gMcCNsHgPsayn/ksVeB9WZ2NXA3cMjdB939PHAI2H0ZP39ehSijA8FERFpYaAA48HMze8PM9oWyq9z9FEC43hzKtwInGh7bF8palU9jZvvMrNfMegcGBhbekyYKUVZTQCIiLUQLrHeHu580s83AITN7f4661qTM5yifXuD+FPAUQE9Pz6z7F6OQy2gKSESkhQWNANz9ZLjuB35GPId/JkztEK77Q/U+YHvDw7cBJ+coXzbFKKvjAEREWpg3AMysw8w669vALuDXwEGgvifPXuD5sH0Q+HrYG+h24GKYInoJ2GVmXWHxd1coWzbxCEABICLSzEKmgK4CfmZm9fp/4+5/b2avA8+a2YPAx8D9of6LwL3AMWAU+AaAuw+a2beA10O9x9x9cMl60oSOAxARaW3eAHD348DNTcrPAXc1KXfgoRbPtR/Yv/hmfjpaBBYRaS3xRwKXqzVqtctaSxYRSaREB0AxF58WslzVKEBEZKZEB0Ahqp8VTOsAIiIzJTsAdF5gEZGWkh0AUTwFpGMBRERmS3QAFCdHAJoCEhGZKdEBUB8B6AvhRERmS3gAaAQgItJKSgJAIwARkZmSHQDhOACNAEREZkt0AEwuAmsNQERklkQHwOQisEYAIiKzJDwANAIQEWklHQGgRWARkVkSHQBFLQKLiLSU6ACY+jI4jQBERGZKdABE2QzZjGkEICLSRKIDAOqnhdQIQERkpnQEgBaBRURmSXwAFHNZTQGJiDSR+AAoRBktAouINLHgADCzrJm9aWYvhNvXmdlrZnbUzH5iZvlQXgi3j4X7dzQ8xyOh/AMzu3upO9NMIdIIQESkmcWMAL4JHGm4/R3gCXffCZwHHgzlDwLn3f23gCdCPczsJuAB4IvAbuAvzSx7ec2fXyGnNQARkWYWFABmtg34PeCH4bYBdwLPhSoHgPvC9p5wm3D/XaH+HuAZdy+5+z8Bx4DblqITcylGWe0FJCLSxEJHAN8D/hSov5NuBC64eyXc7gO2hu2twAmAcP/FUH+yvMljlk0hl9GXwYmINDFvAJjZV4F+d3+jsbhJVZ/nvrke0/jz9plZr5n1DgwMzNe8eek4ABGR5hYyArgD+AMz+wh4hnjq53vAejOLQp1twMmw3QdsBwj3rwMGG8ubPGaSuz/l7j3u3tPd3b3oDs2kRWARkebmDQB3f8Tdt7n7DuJF3Jfd/Y+AV4CvhWp7gefD9sFwm3D/y+7uofyBsJfQdcBO4JdL1pMWtAgsItJcNH+Vlv4b8IyZ/QXwJvB0KH8a+GszO0b8yf8BAHd/18yeBd4DKsBD7r7sH80LUVbHAYiINLGoAHD3XwC/CNvHabIXj7uPA/e3ePzjwOOLbeTliL8KQlNAIiIzJf9IYE0BiYg0lfwAiLKUKzXiZQgREalLfAAUczotpIhIM4kPgEIUTguphWARkWlSEAD1EYAWgkVEGqUoADQCEBFplPgAKObCFJBGACIi0yQ+AOojAB0MJiIyXfIDQCMAEZGmkh8A9TUAjQBERKZJTwBoEVhEZJrEB4AWgUVEmkt8AGgRWESkueQHgEYAIiJNJT8AtAYgItJU4gNgcg1AU0AiItMkPgCm1gA0BSQi0ijxARBljIxpCkhEZKbEB4CZUYiyWgQWEZkh8QEA8UlhNAIQEZkuFQFQiLJaAxARmSEdAaARgIjILPMGgJkVzeyXZvYrM3vXzP48lF9nZq+Z2VEz+4mZ5UN5Idw+Fu7f0fBcj4TyD8zs7uXq1EyFKKPdQEVEZljICKAE3OnuNwO3ALvN7HbgO8AT7r4TOA88GOo/CJx3998Cngj1MLObgAeALwK7gb80s+xSdqYVLQKLiMw2bwB4bDjczIWLA3cCz4XyA8B9YXtPuE24/y4zs1D+jLuX3P2fgGPAbUvSi3loEVhEZLYFrQGYWdbM3gL6gUPAh8AFd6+EKn3A1rC9FTgBEO6/CGxsLG/ymGWlRWARkdkWFADuXnX3W4BtxJ/ab2xWLVxbi/talU9jZvvMrNfMegcGBhbSvHkVIo0ARERmWtReQO5+AfgFcDuw3syicNc24GTY7gO2A4T71wGDjeVNHtP4M55y9x537+nu7l5M81rSXkAiIrMtZC+gbjNbH7bbgN8FjgCvAF8L1fYCz4ftg+E24f6X3d1D+QNhL6HrgJ3AL5eqI3MpahFYRGSWaP4qXA0cCHvsZIBn3f0FM3sPeMbM/gJ4E3g61H8a+GszO0b8yf8BAHd/18yeBd4DKsBD7r4i78qFXEYnhBERmWHeAHD3t4EvNSk/TpO9eNx9HLi/xXM9Djy++GZenkKUpaRFYBGRadJxJLAWgUVEZklVAMRLESIiAmkJgHBWsHJVowARkbp0BMDkWcEUACIidekIgPp5gbUrqIjIpHQEQBgB6BtBRUSmpCIAipMjAAWAiEhdKgJgag1AU0AiInWpCgCNAEREpqQkALQILCIyUzoCIKcRgIjITKkIgGJ9BKA1ABGRSakIAI0ARERmS0cA6DgAEZFZUhIAWgQWEZkpFQFQ1BSQiMgsqQiA+ghAB4KJiExJRQDksoaZRgAiIo1SEQBmprOCiYjMkIoAgPgL4XQcgIjIlNQEQCHK6IQwIiINUhQAWe0GKiLSYN4AMLPtZvaKmR0xs3fN7JuhfIOZHTKzo+G6K5SbmT1pZsfM7G0zu7XhufaG+kfNbO/ydWs2rQGIiEy3kBFABfgTd78RuB14yMxuAh4GDrv7TuBwuA1wD7AzXPYBP4A4MIBHgS8DtwGP1kNjJRRyCgARkUbzBoC7n3L3fwzbQ8ARYCuwBzgQqh0A7gvbe4AfeexVYL2ZXQ3cDRxy90F3Pw8cAnYvaW/mUNQUkIjINItaAzCzHcCXgNeAq9z9FMQhAWwO1bYCJxoe1hfKWpWviEJOi8AiIo0WHABmtgb4O+CP3f3SXFWblPkc5TN/zj4z6zWz3oGBgYU2b15aBBYRmW5BAWBmOeI3/x+7+09D8ZkwtUO47g/lfcD2hodvA07OUT6Nuz/l7j3u3tPd3b2YvsypEGX0baAiIg0WsheQAU8DR9z9uw13HQTqe/LsBZ5vKP962BvoduBimCJ6CdhlZl1h8XdXKFsRxVxWi8AiIg2iBdS5A/j3wDtm9lYo+zPg28CzZvYg8DFwf7jvReBe4BgwCnwDwN0HzexbwOuh3mPuPrgkvViA+EAwTQGJiNTNGwDu/n9pPn8PcFeT+g481OK59gP7F9PApaLjAEREpkvPkcA5LQKLiDRKTwCEEUA8QBERkdQEQDGXxR0mqgoAERFIUQDUTww/rmkgEREghQGgYwFERGIpCoD4vMBaCBYRiaUnAHJhBKBdQUVEgDQFQBgB6GAwEZFYegJAIwARkWnSEwBaBBYRmSZFAaBFYBGRRqkJgGKYAtJJYUREYqkJAI0ARESmS1EAaBFYRKRRegJAewGJiEyTmgAo5sIUkI4DEBEBUhQAmgISEZkuNQGQz9aPA9AIQEQEUhQAZqbTQoqINEhNAEC8DqAAEBGJpSoAClFGXwYnIhKkKwBymgISEambNwDMbL+Z9ZvZrxvKNpjZITM7Gq67QrmZ2ZNmdszM3jazWxseszfUP2pme5enO3MrRFkdCSwiEixkBPBXwO4ZZQ8Dh919J3A43Aa4B9gZLvuAH0AcGMCjwJeB24BH66GxkgpRRt8GKiISzBsA7v4PwOCM4j3AgbB9ALivofxHHnsVWG9mVwN3A4fcfdDdzwOHmB0qy06LwCIiUz7tGsBV7n4KIFxvDuVbgRMN9fpCWavyWcxsn5n1mlnvwMDAp2xec1oEFhGZstSLwNakzOcon13o/pS797h7T3d395I2TscBiIhM+bQBcCZM7RCu+0N5H7C9od424OQc5StKi8AiIlM+bQAcBOp78uwFnm8o/3rYG+h24GKYInoJ2GVmXWHxd1coW1FF7QYqIjIpmq+Cmf0t8BVgk5n1Ee/N823gWTN7EPgYuD9UfxG4FzgGjALfAHD3QTP7FvB6qPeYu89cWF52hSirNQARkWDeAHD3P2xx111N6jrwUIvn2Q/sX1TrlpgOBBMRmZKuI4F1HICIyKSUBUC8CBwPVERE0i1VAVDMZag5TFQVACIiqQqAQhROC6ldQUVEUhYAOjG8iMikdAWAzgssIjIpVQFQzIUpIB0LICKSrgCojwDGtSuoiEjaAkCLwCIidSkLAK0BiIjUpSsAtBeQiMikdAVAmALSF8KJiKQsAIoaAYiITEpVAEwuAmsEICKStgDQCEBEpC5dAVA/EEwBICKSsgCYPBBMU0AiIvOeESxJClGGYi7D9w8f5VcnLvD7N1/DXTdupj2fql+DiAiQsgAwM376H+/guTf6eOHtk/z8vTO05bLcdeNmfv/ma/jnW9dRP1OAu1M/b0wum2F9e27yu4RERJLAruSzY/X09Hhvb++yPHe15rz+0SAvvH2SF985zeBIed7HFHMZ1rflWd+eo6s9T1dHju41BTavLdLdWWBzZ4HNnUU2deaJMhlqIUTcnZqD43QWc3Tks5jZZbW/VnM+uTDGB6eH+ODMEP/vzBAfnB7i+NkR2nJZujsLdK8pTLaru7PA5rUFrlpbZMvaIlvWFaeNfNydS2MV+i6M0nd+jE/Oj3F+tEyUyZCLjHw2Q27yYuSyGaKsxfeH27lshnVtOTatydPVkSeX/WzOMLr7Zf99kmJ8osonF8bY1FFgXXtutZuz5Go159xIma72HNFlvF7r/z+jExU2dxbJZlb39WNmb7h7z7z10hoAjSrVGq8eH+STC6MAGOGPZ2BAuVrjwugEF8cmOD9S5sLYBBdGywyOlBkYKnFpvLKon1fMZdi0pjB56e7MU8xlmajWKFfiy0TVKVVqlCpVShM1xitVxieqjE1UGZ+oMTQ+Me1L7baub+MLWzq5vruDcqVG/1CJgaESA8Ml+i+VGGuy7tFZjNiyNn6x9p0fY7g0vR9mcDkvj/XtOTZ25NnYUaCQyzBRrVGpOpWaU6nF2+7EQZLNkMsYUT1cMnFZviFo8pGRzRiliRqjE1XGy/HvY7Qc/25qobGG0ez920MIx9fxP3+pUqPc8HsvV+Pf6bauNnZs7OC6TR3s2NjOjk0dXLuxA3dntBz/zJFyhdFSldFyBTMjH8XtLUSZeDvK4A6j5Qpj5Soj5Spj5Qqj5am/4/hENf47T1QZr1QpV2qT7YvbPPUH6Czm2NARfwDZ0JGPP4S058lkCM8x9XopVapgxtpixNq2HGuLOda1Rawt5ijksoyWK4yUKgyXquG6wsWxCT45P8aJwVE+Dpf+odLkz79mXZEbrl7LDVs6ueHqtdy4pZP17XlKod2lht/hcKnC4HD8PzI4WmZwuMy5kTIjpQprinE71rZFrAttW1OMqFQ9/F6qjJWnXu9j4fZYQ/louUoum4k/1HQW2bw2/iC2ubPA+rbcZIA3/v5KlRofD47ym3MjfHQuvv7NuVFKlRr5KMPOzWv4wpZObtyyli9s6eSGLZ3kshnOj5bjy8gEg6NlLoyWOTtc5vTFcU5fGudMuNT/H6OMsbWrje1d7Wzf0M7nNrSzrauNjWvi/4WujvgDZP0DUv3D3IcDw3w4MMLxgWE+HBjmX17bxX+9+4ZP9b93xQaAme0Gvg9kgR+6+7db1V2pALhc4xNVBoZK9A+N03+pxNnhEjWP30DNjIxNvSldGpvg7HCJs8NxeMTbJUoT8Yswl51686hvt+UyFHNZilGWtnyWYi5DRz7i893xC/afXbWGzuLcn86GS5X4hRpetKcbtqs1Z1tXO1vXt7Gtq42tXW1sXd/Gho58OIVmLVx8MqQmqjUqNW94U69RrjgXx+J/jnPDZc6NlDg3XObscImJao0ok5l8s48yRpSJfyeVqjNRcyrhuSZCOMz8GRPVGtWax2s5+Szt+SxtuWz8u8lliTI2+SYPTL6R1rPAGv4OZpAJb9qF8MZd/73XHD4eHOWjsyN8dHaEkfLy7DRQ/9lx+zMUoyz5KEOmIb3qmzV3hscrDI6UF/2BYzHM4Jp1bWzf0MbnwpvXNevb6B8q8f6pS7x/eohj/cNUagt/34gyxoaOPBs68qwpRAyXKgyNV7g0NsFQqXlfMsa0v217Pn7tt+WmrkuVGv1D45y5VOJc+J9biEKU4dqN7Vy7MQ73q9e1ceriGO+fHuL900MMNIReK/koE4+k1xa5al2RLWF03ZbP8sn5MT4eHOVECNNWswtrixHr2nP0XypN2zNxXVuO67s72PXFLfyHf3P9wjo1w0IDYEXXAMwsC/xP4N8CfcDrZnbQ3d9byXYstWIuy/YNcdpfqdYUItZ0r+H67jWLelzWIJvJpnb9w90ZGC7x0dlRTgyOEmWNtlyWjkJEWz5LRz6iPZ/FHcrV6tSn4PBJ2LC4XiFLey5+TD24Mp9ymqBSrXEhjEYHR8rUPP6eq2KUpZCLQ6UQZeNpifEKl8YnuDQ2EW+PTTA+UaU9H9FRyMavi0JERyH+VH7VusLkAZOtlCs1PhwY5v3TlxguVSmE8Gwc+bTns2zoKLChI8/aYtRySq0SRgtD4xXyDWGYz2YWNQ1XqdYYHClz5lKJi2MT00aA9c0om2FbVxtb1hbn/N0PjpR5//QlPjg9hDuTn9i72vOTI7A1hdZ9mmm4VOGT82OcGynFo4iREoPh+sLYBJs7C1zfvYbPd6/h+u4ONnTkV2wKckVHAGb228B/d/e7w+1HANz9fzSr/1kZAYiIXEkWOgJY6VW6rcCJhtt9oUxERFbYSgdAs3HNtCGIme0zs14z6x0YGFihZomIpM9KB0AfsL3h9jbgZGMFd3/K3Xvcvae7u3tFGycikiYrHQCvAzvN7DozywMPAAdXuA0iIsIK7wXk7hUz+0/AS8S7ge5393dXsg0iIhJb8a+CcPcXgRdX+ueKiMh0n81j9UVE5LIpAEREUuqK/i4gMxsAfnMZT7EJOLtEzfksUb/TRf1Ol4X0+1p3n3c3yis6AC6XmfUu5Gi4pFG/00X9Tpel7LemgEREUkoBICKSUkkPgKdWuwGrRP1OF/U7XZas34leAxARkdaSPgIQEZEWEhkAZrbbzD4ws2Nm9vBqt2e5mNl+M+s3s183lG0ws0NmdjRcd61mG5eDmW03s1fM7IiZvWtm3wzlie67mRXN7Jdm9qvQ7z8P5deZ2Wuh3z8J37OVOGaWNbM3zeyFcDst/f7IzN4xs7fMrDeULclrPXEB0HDWsXuAm4A/NLObVrdVy+avgN0zyh4GDrv7TuBwuJ00FeBP3P1G4HbgofA3TnrfS8Cd7n4zcAuw28xuB74DPBH6fR54cBXbuJy+CRxpuJ2WfgP8jrvf0rD755K81hMXAMBtwDF3P+7uZeAZYM8qt2lZuPs/AIMzivcAB8L2AeC+FW3UCnD3U+7+j2F7iPhNYSsJ77vHhsPNXLg4cCfwXChPXL8BzGwb8HvAD8NtIwX9nsOSvNaTGABpP+vYVe5+CuI3SmDzKrdnWZnZDuBLwGukoO9hGuQtoB84BHwIXHD3+tnVk/p6/x7wp0D97OkbSUe/IQ75n5vZG2a2L5QtyWt9xb8NdAXMe9YxSQYzWwP8HfDH7n5ppU6kvZrcvQrcYmbrgZ8BNzartrKtWl5m9lWg393fMLOv1IubVE1Uvxvc4e4nzWwzcMjM3l+qJ07iCGDes44l3BkzuxogXPevcnuWhZnliN/8f+zuPw3Fqeg7gLtfAH5BvAay3szqH+aS+Hq/A/gDM/uIeEr3TuIRQdL7DYC7nwzX/cShfxtL9FpPYgCk/axjB4G9YXsv8PwqtmVZhPnfp4Ej7v7dhrsS3Xcz6w6f/DGzNuB3idc/XgG+Fqolrt/u/oi7b3P3HcT/zy+7+x+R8H4DmFmHmXXWt4FdwK9Zotd6Ig8EM7N7iT8h1M869vgqN2lZmNnfAl8h/nbAM8CjwP8GngU+B3wM3O/uMxeKP9PM7F8B/wd4h6k54T8jXgdIbN/N7F8QL/hliT+8Pevuj5nZ54k/GW8A3gT+nbuXVq+lyydMAf0Xd/9qGvod+vizcDMC/sbdHzezjSzBaz2RASAiIvNL4hSQiIgsgAJARCSlFAAiIimlABARSSkFgIhISikARERSSgEgIpJSCgARkZT6/0FKTTpqEHdaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.3198084 ],\n",
       "       [ 5.07402485],\n",
       "       [10.4281115 ],\n",
       "       [ 5.97012463],\n",
       "       [ 5.23506546],\n",
       "       [ 9.22472738],\n",
       "       [ 8.56420795],\n",
       "       [ 4.3360556 ],\n",
       "       [ 5.76495039],\n",
       "       [ 4.90587072]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

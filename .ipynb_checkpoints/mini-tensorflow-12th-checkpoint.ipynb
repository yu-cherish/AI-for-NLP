{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []# 接受输入接受输出\n",
    "        \n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes outbound_nodes\n",
    "            \n",
    "        self.value = None\n",
    "        \n",
    "        self.gradients = {\n",
    "            # if is wx+b, this will be \n",
    "            # w: x 对w求偏导是x\n",
    "            # x: w 对x求偏导是w\n",
    "            # b: 1 对b求偏导是1\n",
    "        }\n",
    "        \"\"\"keys are the inputs to this node;\n",
    "        their values are the partials of this node with respect to that input \n",
    "        \\partial{node}{input_i} key是节点的输入，key对应的value是该节点对应于输入的部分\"\"\"\n",
    "        \n",
    "    def forward(self):\n",
    "        \"\"\"\n",
    "        forward propagation\n",
    "        compute the output value on 'inbound_nodes' and store the result in self.value\n",
    "        前向传播\n",
    "        计算输入节点的输出值并在self.value上存储结果\n",
    "        \"\"\"\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def backward(self):\n",
    "        raise NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        an input node has no inbound nodes\n",
    "        so no need to pass anything to the node instantiator(实例化？)\n",
    "        没有输入节点的输入节点\n",
    "\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "        \n",
    "    def forward(self, value=None):\n",
    "\n",
    "#         Only input node is the node where the value may be passed as an argument to forward().\n",
    "#         All other node implementations should get the value of the previous node from self.inbound_nodes\n",
    "        \n",
    "#         Example: \n",
    "#         val0: self.inbound_nodes[0].value\n",
    "\n",
    "        if value is not None:\n",
    "            self.value = value # 也可等于2* value等等不一样的计算方式\n",
    "            # 这是输入节点，当需要前向传播时，这个节点初始化自己的值\n",
    "         # 输入仅有值的子类，例如数据特征或者一个模型参数（权重、偏置项）\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1 \n",
    "            \n",
    "         # 输入N --> N1, N2 \n",
    "         # \\partial L / \\partial N \n",
    "         # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Add(Node):\n",
    "    \n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "        \n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        # 执行Forward时，此节点根据定义计算值\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    \n",
    "    def  __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "        \n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "        \n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "        \n",
    "        # 为每一个出入节点初始化一个partial(偏置)偏导数\n",
    "        # initial a partial for each of the inbound_nodes\n",
    "        # np.zeros_like(n.value)为每个n.value生成一个同类型同样子的元素都是0的矩阵\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            # get the partial of the cost w.r.t this node\n",
    "            grad_cost = n.gradients[self] # 偏f/self\n",
    "            \n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            # 后面value.T 是因为考虑到numpy中数组的形状，对x求偏导\n",
    "            \n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            # 对w求偏导 偏f/偏linear * 偏linear/偏w\n",
    "            \n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "            # 对b求偏导  偏f/偏linear * 偏linear/偏w=偏f/偏linear * 1=grad_cost\n",
    "            # np.sum默认axis为None，表示将所有元素的值相加.对于二维数组,axis=1表示按行相加\n",
    "            # , axis=0表示按列相加\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "        \n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "    \n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^ -x)\n",
    "        # y' = y(1 - y)\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "        \n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            # get the partial of the cost with respect to this node\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to 保持所有的维度一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "        \n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "        \n",
    "        self.m = self.inputs[0].value.shape[0] # 表示y的元素个数\n",
    "        self.diff = y - a\n",
    "        \n",
    "        self.value = np.mean(self.diff ** 2)\n",
    "        # np.mean 求均值  axis=0、1，计算每一列、行的均值  1/m（y-a）^ 2\n",
    "        \n",
    "    def backward(self):\n",
    "        # 以下两个分别是对y求偏导，对a也就是yhat求偏导\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(outputnode, graph):\n",
    "    \n",
    "    # 运行排序节点的所有forward方法\n",
    "    # 实际应用中，经常有大量的数据而不是1个通过forward方法。因为样本可以并行处理。\n",
    "    # batch_size表示依次进入forward函数的样本的数量\n",
    "    \n",
    "    \n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        # 每个节点运行forward方法，依据拓扑排序的结果获得self.value\n",
    "    \n",
    "    for n in graph[::-1]:\n",
    "        n.backward()\n",
    "        \n",
    "    # 返回 outputnode.value\n",
    "    \n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"使用Kahn算法按拓扑顺序对一般节点排序。\n",
    "    ` feed_dict`：一种字典，其中key是“input”节点，value是向该节点提供的相应的值。\n",
    "     返回已排序节点的列表。 \"\"\"\n",
    "    \n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "    \n",
    "    G = {}\n",
    "    \n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out':set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "            \n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    \n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "        \n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            # 如果n是输入节点，把n的value设置为feed_dict[n]\n",
    "            # 否则，n的value通过他的输入来计算\n",
    "            \n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # 如果没有其他 引入的边添加到S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "                \n",
    "    return L\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # 有很多种更新、最优化方法，例如Adam，Mom\n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of examples = 506\n",
      "Epoch: 1, Loss: 150.800\n",
      "Epoch: 101, Loss: 7.678\n",
      "Epoch: 201, Loss: 5.116\n",
      "Epoch: 301, Loss: 5.605\n",
      "Epoch: 401, Loss: 3.879\n",
      "Epoch: 501, Loss: 4.294\n",
      "Epoch: 601, Loss: 3.695\n",
      "Epoch: 701, Loss: 3.993\n",
      "Epoch: 801, Loss: 3.319\n",
      "Epoch: 901, Loss: 3.396\n",
      "Epoch: 1001, Loss: 3.246\n",
      "Epoch: 1101, Loss: 3.118\n",
      "Epoch: 1201, Loss: 3.374\n",
      "Epoch: 1301, Loss: 3.231\n",
      "Epoch: 1401, Loss: 3.434\n",
      "Epoch: 1501, Loss: 3.135\n",
      "Epoch: 1601, Loss: 3.302\n",
      "Epoch: 1701, Loss: 3.678\n",
      "Epoch: 1801, Loss: 2.803\n",
      "Epoch: 1901, Loss: 3.459\n",
      "Epoch: 2001, Loss: 3.323\n",
      "Epoch: 2101, Loss: 3.109\n",
      "Epoch: 2201, Loss: 2.866\n",
      "Epoch: 2301, Loss: 3.085\n",
      "Epoch: 2401, Loss: 3.186\n",
      "Epoch: 2501, Loss: 3.120\n",
      "Epoch: 2601, Loss: 2.876\n",
      "Epoch: 2701, Loss: 3.489\n",
      "Epoch: 2801, Loss: 3.010\n",
      "Epoch: 2901, Loss: 3.020\n",
      "Epoch: 3001, Loss: 3.537\n",
      "Epoch: 3101, Loss: 3.326\n",
      "Epoch: 3201, Loss: 3.345\n",
      "Epoch: 3301, Loss: 3.239\n",
      "Epoch: 3401, Loss: 3.257\n",
      "Epoch: 3501, Loss: 2.914\n",
      "Epoch: 3601, Loss: 3.071\n",
      "Epoch: 3701, Loss: 3.275\n",
      "Epoch: 3801, Loss: 3.321\n",
      "Epoch: 3901, Loss: 2.713\n",
      "Epoch: 4001, Loss: 2.905\n",
      "Epoch: 4101, Loss: 2.761\n",
      "Epoch: 4201, Loss: 3.127\n",
      "Epoch: 4301, Loss: 2.629\n",
      "Epoch: 4401, Loss: 3.031\n",
      "Epoch: 4501, Loss: 2.864\n",
      "Epoch: 4601, Loss: 2.739\n",
      "Epoch: 4701, Loss: 2.671\n",
      "Epoch: 4801, Loss: 2.962\n",
      "Epoch: 4901, Loss: 3.135\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "选择新的网络架构和数据集。注意到权重和偏置是随机生成的。\n",
    "不需要改变任何事情，但可以随意调整来测试您的网络，play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "\n",
    "# load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0) # std是标准差 mean是求均值\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden,1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "\n",
    "# 样本总数\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print('total number of examples = {}'.format(m))\n",
    "\n",
    "# step4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # step1 随机抽取一批样本 randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size) \n",
    "        # resample重新取样 参数n_sample是生成样本的数量\n",
    "        \n",
    "        # Reset value of X and y Inputs 重置x和y的输入值\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "        \n",
    "        # step2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # 设置不重要的输出节点\n",
    "        \n",
    "        #step3\n",
    "        rate = 1e-2\n",
    "        \n",
    "        sgd_update(trainables,rate)\n",
    "        \n",
    "        loss += graph[-1].value\n",
    "        \n",
    "    if i % 100 == 0:\n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1e350d390b8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.93429859],\n",
       "       [ 6.80057843],\n",
       "       [10.59621132],\n",
       "       [ 5.5488751 ],\n",
       "       [ 8.74056616],\n",
       "       [11.27823367],\n",
       "       [ 4.67913947],\n",
       "       [ 8.9879092 ],\n",
       "       [-6.50772489],\n",
       "       [ 9.92723831]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

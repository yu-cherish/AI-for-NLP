{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model using News corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../Data_source/80k_articles.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_content = open(filename, encoding='UTF-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34475997"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = all_content[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(string):\n",
    "    return ''.join(re.findall('[\\w]+',string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'新华社照片东莞广东2017年4月7日n体育9篮球CBA总决赛第四场广东对阵新疆n4月7日广东东莞银行队球员易建联在比赛中扣篮n当日在20162017赛季中国男子篮球职业联赛CBA总决赛第四场比赛中广东东莞银行队主场迎战新疆喀什古城队n新华社记者孟永民摄n新华社北京４月１４日新媒体专电记者杨烨作为国民经济的重要支柱央企一季度交上了一份漂亮的'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(W_oW_1W_2Wn) = P(W_o) \\cdot P(W_1) \\cdot P(W_2) \\cdot P(W_n) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_character = tokenize(all_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_character_counts = Counter(all_character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 635684),\n",
       " ('n', 605563),\n",
       " ('国', 303683),\n",
       " ('1', 285430),\n",
       " ('在', 273451),\n",
       " ('一', 255874),\n",
       " ('中', 249541),\n",
       " ('日', 248419),\n",
       " ('2', 247140),\n",
       " ('新', 243975)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_character_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_from_counts(counts):\n",
    "    all_occurences = sum(counts.values())\n",
    "    def get_prob(items):\n",
    "        return counts[items] / all_occurences\n",
    "    return get_prob  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_char_prob = get_probability_from_counts(all_character_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_of_string(string):\n",
    "    return reduce(mul,[get_char_prob(c) for c in string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = \"\"\"前天晚上吃晚饭的时候\n",
    "前天晚上吃早饭的时候\"\"\".split('\\n')\n",
    "\n",
    "pair2 = \"\"\"正是一个好看的小猫\n",
    "真是一个好看的小猫\"\"\".split('\\n')\n",
    "\n",
    "pair3 = \"\"\"我无言以对，简直\n",
    "我简直无言以对\"\"\".split('\\n')\n",
    "\n",
    "pairs = [pair, pair2, pair3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_prefromance(language_model_func, pairs):\n",
    "    for (p1, p2) in pairs:\n",
    "        print('*'*18)\n",
    "        print('\\t\\t {} with probability {}'.format(p1, language_model_func(tokenize(p1))))\n",
    "        print('\\t\\t {} with probability {}'.format(p2, language_model_func(tokenize(p2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "\t\t 前天晚上吃晚饭的时候 with probability 1.2207058723774045e-31\n",
      "\t\t 前天晚上吃早饭的时候 with probability 1.420433440421635e-31\n",
      "******************\n",
      "\t\t 正是一个好看的小猫 with probability 3.2528612289150613e-25\n",
      "\t\t 真是一个好看的小猫 with probability 1.0220793879946632e-25\n",
      "******************\n",
      "\t\t 我无言以对，简直 with probability 3.7425390630342124e-22\n",
      "\t\t 我简直无言以对 with probability 3.742539063034212e-22\n"
     ]
    }
   ],
   "source": [
    "get_probability_prefromance(prob_of_string, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2745292803369746e-36\n",
      "2.0995356460752042e-33\n"
     ]
    }
   ],
   "source": [
    "print(prob_of_string('广州有一个地方叫做沥窖'))\n",
    "print(prob_of_string('杭州有一个地方叫做西湖'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functional programming in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_some_num(num1):\n",
    "    def _add(num2):\n",
    "        return num1 + num2\n",
    "    return _add\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ten = add_some_num(10)\n",
    "add_twenty = add_some_num(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(add_ten(11))\n",
    "print(add_twenty(11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pr(w_ow_1w_2...w_n) = Pr(w_1 | w_0) \\cdot Pr(w_2 | w_1) ... \\cdot Pr(w_n | w_{n-1})  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ Pr(w_1 | w_0) = \\frac{Pr(w_1 w_0)}{Pr(w_0)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_length = 2\n",
    "two_gram_counts = Counter([all_character[i:i+gram_length] for i in range(len(all_character)-gram_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('新华', 135490),\n",
       " ('华社', 129104),\n",
       " ('20', 123427),\n",
       " ('nn', 118789),\n",
       " ('01', 102583),\n",
       " ('17', 81801),\n",
       " ('n新', 78433),\n",
       " ('中国', 77776),\n",
       " ('外代', 74795),\n",
       " ('7年', 59051)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pair_prob = get_probability_from_counts(two_gram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2gram_prob(prev,word):\n",
    "    if get_pair_prob(prev+word) > 0:\n",
    "        return get_pair_prob(prev+word)/get_char_prob(prev)\n",
    "    else:\n",
    "        return get_char_prob(prev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2gram_string_prob(string):\n",
    "    probability = []\n",
    "    for i,c in enumerate(string):\n",
    "        prev = 'n' if i == 0 else string[i-1]\n",
    "        probability.append(get_2gram_prob(prev,c))\n",
    "    return reduce(mul,probability)\n",
    "    #return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pair = ['发表了重要的讲话', '发表了重要的僵化']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.204612960989359e-16"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_2gram_string_prob(string_pair[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.303640669954108e-18"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_2gram_string_prob(string_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "\t\t 前天晚上吃晚饭的时候 with probability 2.6234499089924518e-23\n",
      "\t\t 前天晚上吃早饭的时候 with probability 6.698347779288344e-23\n",
      "******************\n",
      "\t\t 正是一个好看的小猫 with probability 6.899582699458634e-20\n",
      "\t\t 真是一个好看的小猫 with probability 8.457208248607783e-21\n",
      "******************\n",
      "\t\t 我无言以对，简直 with probability 8.241868374267051e-20\n",
      "\t\t 我简直无言以对 with probability 7.969727269316052e-20\n"
     ]
    }
   ],
   "source": [
    "get_probability_prefromance(get_2gram_string_prob, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Model using Wikipedia data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from opencc import OpenCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_CN_char(ch):\n",
    "    return ch >= u'\\u4e00' and ch <= u'\\u9fa5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert2simple(word):\n",
    "    openCC = OpenCC('tw2sp')\n",
    "    return openCC.convert(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanhtml(raw_html):\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', raw_html)\n",
    "    return cleantext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansymbol(words):\n",
    "    result = ['$']\n",
    "    for word in words:\n",
    "        if is_CN_char(word) or word in '，、；：':\n",
    "            result.append(word)\n",
    "        if word in '。？！':\n",
    "            result.append(word)\n",
    "            result.append('$')\n",
    "    return result       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_process(data):\n",
    "    clean = cleanhtml(content)\n",
    "    converted = convert2simple(clean)\n",
    "    line = cleansymbol(converted)\n",
    "    return ''.join(line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki2txt(filename):\n",
    "    output = open('wiki_seg.txt', 'a', encoding='utf-8')\n",
    "    for root, dirs, files in os.walk(filename):\n",
    "        for filename in files:\n",
    "            file_path = root + '/' + filename\n",
    "            content = open(file_path, encoding='UTF-8').read()\n",
    "            result = data_process(content)\n",
    "            output.write(result)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki2txt(filename):\n",
    "    output = open('wiki_seg.txt', 'a', encoding='utf-8')\n",
    "    for root, dirs, files in os.walk(filename):\n",
    "        for filename in files:\n",
    "            file_path = root + '/' + filename\n",
    "            content = open(file_path, encoding='UTF-8').read()\n",
    "            clean = cleanhtml(content)\n",
    "            converted = convert2simple(clean)\n",
    "            line = cleansymbol(converted)\n",
    "            output.write(''.join(line))\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki2txt(\"../Data_source/wiki_zh/AA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigram        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = open('wiki_seg.txt', encoding='UTF-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_counts = Counter(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('，', 1733047),\n",
       " ('的', 1247374),\n",
       " ('$', 959624),\n",
       " ('。', 953526),\n",
       " ('、', 442447),\n",
       " ('年', 382463),\n",
       " ('在', 365549),\n",
       " ('为', 350941),\n",
       " ('一', 350413),\n",
       " ('国', 347783)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_from_count(counts):\n",
    "    all_occurences = sum(counts.values())\n",
    "    def get_prob(item):\n",
    "        return counts[item]/all_occurences\n",
    "    return get_prob   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_char_prob = get_probability_from_count(char_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_of_sentence(string):\n",
    "    return reduce(mul,[get_char_prob(c) for c in string])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "\t\t 前天晚上吃晚饭的时候 with probability 3.4006591032847233e-32\n",
      "\t\t 前天晚上吃早饭的时候 with probability 9.504178445822157e-32\n",
      "******************\n",
      "\t\t 正是一个好看的小猫 with probability 9.242154922773662e-26\n",
      "\t\t 真是一个好看的小猫 with probability 2.883752707827827e-26\n",
      "******************\n",
      "\t\t 我无言以对，简直 with probability 8.936504790621565e-22\n",
      "\t\t 我简直无言以对 with probability 8.936504790621565e-22\n"
     ]
    }
   ],
   "source": [
    "get_probability_prefromance(get_prob_of_sentence, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_length = 2\n",
    "two_gram_counts = Counter([content[i:i+gram_length] for i in range(len(content)-gram_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('。$', 953526),\n",
       " ('$年', 102911),\n",
       " ('年月', 79523),\n",
       " ('月日', 63989),\n",
       " ('中国', 60797),\n",
       " ('年，', 57733),\n",
       " ('一个', 55836),\n",
       " ('，并', 49650),\n",
       " ('$在', 48974),\n",
       " ('，但', 48552)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_gram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pair_prob = get_probability_from_counts(two_gram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2gram_prob(prev,word):\n",
    "    if get_pair_prob(prev+word) > 0:\n",
    "        return get_pair_prob(prev+word)/get_char_prob(prev)\n",
    "    else:\n",
    "        return get_char_prob(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2gram_prob_of_sentence(string):\n",
    "    probability = []\n",
    "    for i in range(len(string)-1):\n",
    "        probability.append(get_2gram_prob(string[i],string[i+1]))\n",
    "    return reduce(mul,probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "\t\t 前天晚上吃晚饭的时候 with probability 3.9332378822471356e-21\n",
      "\t\t 前天晚上吃早饭的时候 with probability 6.823461930353542e-22\n",
      "******************\n",
      "\t\t 正是一个好看的小猫 with probability 2.787742595269777e-17\n",
      "\t\t 真是一个好看的小猫 with probability 9.6313544690318e-18\n",
      "******************\n",
      "\t\t 我无言以对，简直 with probability 1.0727257212925853e-16\n",
      "\t\t 我简直无言以对 with probability 8.572784175554936e-18\n"
     ]
    }
   ],
   "source": [
    "get_probability_prefromance(get_2gram_prob_of_sentence, pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word level bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Anan\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.739 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "words = cut(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gram_length = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "WordLevel_2gram_counts = Counter([words[i]+words[i+gram_length] for i in range(len(words)-gram_length)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的，', 192291),\n",
       " ('的。', 148494),\n",
       " ('、、', 129461),\n",
       " ('$，', 97978),\n",
       " ('。年', 73416),\n",
       " ('。在', 47928),\n",
       " ('，的', 47868),\n",
       " ('$的', 46121),\n",
       " ('，在', 43134),\n",
       " ('，是', 31226)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WordLevel_2gram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('，', 1733047),\n",
       " ('的', 1236718),\n",
       " ('$', 959624),\n",
       " ('。', 953526),\n",
       " ('、', 442447),\n",
       " ('在', 321409),\n",
       " ('是', 230373),\n",
       " ('年', 207907),\n",
       " ('和', 194577),\n",
       " ('了', 160284)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_word_prob = get_probability_from_counts(word_counts)\n",
    "get_pair_prob = get_probability_from_counts(WordLevel_2gram_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WordLevel_2gram_prob(prev,word):\n",
    "    if get_pair_prob(prev+word) > 0:\n",
    "        return get_pair_prob(prev+word)/get_word_prob(prev)\n",
    "    else:\n",
    "        return get_word_prob(prev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_WordLevel_2gram_prob_of_sentence(string):\n",
    "    probability = []\n",
    "    for i in range(len(string)-1):\n",
    "        probability.append(get_WordLevel_2gram_prob(string[i],string[i+1]))\n",
    "    return reduce(mul,probability)\n",
    "    #return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_prefromance(language_model_func, pairs):\n",
    "    for (p1, p2) in pairs:\n",
    "        print('*'*18)\n",
    "        print('\\t\\t {} with probability {}'.format(p1, language_model_func(cut(p1))))\n",
    "        print('\\t\\t {} with probability {}'.format(p2, language_model_func(cut(p2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************\n",
      "\t\t 前天晚上吃晚饭的时候 with probability 2.7891100676209766e-22\n",
      "\t\t 前天晚上吃早饭的时候 with probability 2.5980227553882673e-26\n",
      "******************\n",
      "\t\t 正是一个好看的小猫 with probability 3.3219131668687725e-18\n",
      "\t\t 真是一个好看的小猫 with probability 1.6929894627554645e-20\n",
      "******************\n",
      "\t\t 我无言以对，简直 with probability 1.552385392458882e-15\n",
      "\t\t 我简直无言以对 with probability 1.0248977613776488e-09\n"
     ]
    }
   ],
   "source": [
    "get_probability_prefromance(get_WordLevel_2gram_prob_of_sentence, pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pair = ['发表了重要的讲话', '发表了重要的僵化']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2768872047325275e-23\n",
      "3.169456250569292e-30\n"
     ]
    }
   ],
   "source": [
    "print(get_WordLevel_2gram_prob_of_sentence(string_pair[0]))\n",
    "print(get_WordLevel_2gram_prob_of_sentence(string_pair[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
